{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7679bdbd-2eeb-43e8-8ffc-becd7c1b2d99",
   "metadata": {},
   "source": [
    "# Diving into data\n",
    "The first task in any data science or ML project is to understand and clean the data.\n",
    "\n",
    "* Understand the data types for each feature\n",
    "* Look for anomalies and missing values\n",
    "* Understand the distributions for each feature\n",
    "\n",
    "![examplegen1.png](img/examplegen1.png)\n",
    "![examplegen2.png](img/examplegen2.png)\n",
    "\n",
    "* [ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen) ingests and splits the input dataset.\n",
    "* [StatisticsGen](https://www.tensorflow.org/tfx/guide/statsgen) calculates statistics for the dataset.\n",
    "* [SchemaGen](https://www.tensorflow.org/tfx/guide/schemagen) examines the statistics and creates a data schema.\n",
    "* [ExampleValidator](https://www.tensorflow.org/tfx/guide/exampleval) looks for anomalies and missing values in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc9967-0024-4220-af82-acb8e596aa3a",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "\n",
    "Use the code below to run TensorFlow Data Validation on your pipeline.  Start by importing and opening the metadata store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e6cef-61ce-4816-b173-520ebb06ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "!pip install -q papermill\n",
    "!pip install -q matplotlib\n",
    "!pip install -q networkx\n",
    "\n",
    "import os\n",
    "import tfx_utils\n",
    "%matplotlib notebook\n",
    "\n",
    "def _make_default_sqlite_uri(pipeline_name):\n",
    "    return os.path.join(os.environ['HOME'], 'airflow/tfx/metadata', pipeline_name, 'metadata.db')\n",
    "\n",
    "def get_metadata_store(pipeline_name):\n",
    "    return tfx_utils.TFXReadonlyMetadataStore.from_sqlite_db(_make_default_sqlite_uri(pipeline_name))\n",
    "\n",
    "pipeline_name = 'taxi'\n",
    "\n",
    "pipeline_db_path = _make_default_sqlite_uri(pipeline_name)\n",
    "print('Pipeline DB:\\n{}'.format(pipeline_db_path))\n",
    "\n",
    "store = get_metadata_store(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c493b-e56e-42f1-b840-d51267fe21bb",
   "metadata": {},
   "source": [
    "**Now print out the data artifacts:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a58cc-8011-46e6-8b9f-280beb9d7d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize properties of example artifacts\n",
    "store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.EXAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e83fa3-be13-4e49-ad97-7dfedcb3b805",
   "metadata": {},
   "source": [
    "**Now visualize the dataset features.**\n",
    "\n",
    "_Hint: try ID 2 or 3_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d42a0-3ab9-4df0-a0ae-83669a658316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stats for data\n",
    "store.display_stats_for_examples(1, split='Split-train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019affb-65d6-4d73-9384-508d0eb0ce68",
   "metadata": {},
   "source": [
    "**Now plot the artifact lineage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab1ea5-c0f3-4d45-aefd-52a4474d6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different IDs here. Click stop in the plot when changing IDs.\n",
    "%matplotlib inline\n",
    "store.plot_artifact_lineage(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c7f74-834f-4d41-818e-d729cae91617",
   "metadata": {},
   "source": [
    "<!--- ![notebook-step3-stats.png](img/notebook-step3-stats.png) --->\n",
    "\n",
    "#### More advanced example\n",
    "The example presented here is really only meant to get you started. For a more advanced example see the [TensorFlow Data Validation Colab](https://www.tensorflow.org/tfx/tutorials/data_validation/chicago_taxi).\n",
    "For more information on using TFDV to explore and validate a dataset, [see the examples on tensorflow.org](https://www.tensorflow.org/tfx/data_validation/get_started)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc686f-4cd1-4ae9-b68f-020ea38820d8",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "You can increase the predictive quality of your data and/or reduce dimensionality with feature engineering.\n",
    "* Feature crosses\n",
    "* Vocabularies\n",
    "* Embeddings\n",
    "* PCA\n",
    "* Categorical encoding\n",
    "\n",
    "One of the benefits of using TFX is that you will write your transformation code once, and the resulting transforms will be consistent between training and serving.\n",
    "\n",
    "![transform.png](img/transform.png)\n",
    "\n",
    "[Transform](https://www.tensorflow.org/tfx/guide/transform) performs feature engineering on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f947a-88df-4f5d-adf6-6770723e904f",
   "metadata": {},
   "source": [
    "Use the code below to run TensorFlow Transform on some example data using the schema from your pipeline. Start by importing and opening the metadata store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5555520-2eae-4751-94e7-12b3db31e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform import beam as tft_beam\n",
    "import tfx_utils\n",
    "from tfx.utils import io_utils\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "# For DatasetMetadata boilerplate\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "def _make_default_sqlite_uri(pipeline_name):\n",
    "    return os.path.join(os.environ['HOME'], 'airflow/tfx/metadata', pipeline_name, 'metadata.db')\n",
    "\n",
    "def get_metadata_store(pipeline_name):\n",
    "    return tfx_utils.TFXReadonlyMetadataStore.from_sqlite_db(_make_default_sqlite_uri(pipeline_name))\n",
    "\n",
    "pipeline_name = 'taxi'\n",
    "\n",
    "pipeline_db_path = _make_default_sqlite_uri(pipeline_name)\n",
    "print('Pipeline DB:\\n{}'.format(pipeline_db_path))\n",
    "\n",
    "store = get_metadata_store(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd4914-e1c9-480b-84a6-130c58693848",
   "metadata": {},
   "source": [
    "**Get the schema URI from the metadata store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc488c-f622-42b9-8ac0-5320b0d70af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the schema URI from the metadata store\n",
    "schemas = store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.SCHEMA)\n",
    "print(schemas.URI)\n",
    "schema_uri = schemas.URI.iloc[0] + '/schema.pbtxt'\n",
    "print ('Schema URI:\\n{}'.format(schema_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9561546-29a3-447e-b74e-1061c3a18b83",
   "metadata": {},
   "source": [
    "**Get the schema that was inferred by TensorFlow Data Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51977d-bff1-4779-8f82-c888d0f18efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_proto = io_utils.parse_pbtxt_file(file_name=schema_uri, message=schema_pb2.Schema())\n",
    "feature_spec, domains = schema_utils.schema_as_feature_spec(schema_proto)\n",
    "legacy_metadata = dataset_metadata.DatasetMetadata(schema_utils.schema_from_feature_spec(feature_spec, domains))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95981634-b6aa-425a-ba8f-4285e6c5a959",
   "metadata": {},
   "source": [
    "**Define features and create functions for TensorFlow Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc968b-ea66-4817-bac5-e61af30240ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features are assumed to each have a maximum value in the dataset.\n",
    "_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
    "\n",
    "_NUMERICAL_FEATURES = ['trip_miles', 'fare', 'trip_seconds']\n",
    "\n",
    "_BUCKET_FEATURES = [\n",
    "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "    'dropoff_longitude'\n",
    "]\n",
    "# Number of buckets used by tf.transform for encoding each feature.\n",
    "_FEATURE_BUCKET_COUNT = 10\n",
    "\n",
    "_CATEGORICAL_NUMERICAL_FEATURES = [\n",
    "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
    "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
    "    'dropoff_community_area'\n",
    "]\n",
    "\n",
    "_CATEGORICAL_STRING_FEATURES = [\n",
    "    'payment_type',\n",
    "    'company',\n",
    "]\n",
    "\n",
    "# Number of vocabulary terms used for encoding categorical features.\n",
    "_VOCAB_SIZE = 1000\n",
    "\n",
    "# Count of out-of-vocab buckets in which unrecognized categorical are hashed.\n",
    "_OOV_SIZE = 10\n",
    "\n",
    "# Keys\n",
    "_LABEL_KEY = 'tips'\n",
    "_FARE_KEY = 'fare'\n",
    "\n",
    "\n",
    "def t_name(key):\n",
    "  \"\"\"\n",
    "  Rename the feature keys so that they don't clash with the raw keys when\n",
    "  running the Evaluator component.\n",
    "  Args:\n",
    "    key: The original feature key\n",
    "  Returns:\n",
    "    key with '_xf' appended\n",
    "  \"\"\"\n",
    "  return key + '_xf'\n",
    "\n",
    "\n",
    "def _make_one_hot(x, key):\n",
    "  \"\"\"Make a one-hot tensor to encode categorical features.\n",
    "  Args:\n",
    "    X: A dense tensor\n",
    "    key: A string key for the feature in the input\n",
    "  Returns:\n",
    "    A dense one-hot tensor as a float list\n",
    "  \"\"\"\n",
    "  integerized = tft.compute_and_apply_vocabulary(x,\n",
    "          top_k=_VOCAB_SIZE,\n",
    "          num_oov_buckets=_OOV_SIZE,\n",
    "          vocab_filename=key, name=key)\n",
    "  depth = (\n",
    "      tft.experimental.get_vocabulary_size_by_name(key) + _OOV_SIZE)\n",
    "  one_hot_encoded = tf.one_hot(\n",
    "      integerized,\n",
    "      depth=tf.cast(depth, tf.int32),\n",
    "      on_value=1.0,\n",
    "      off_value=0.0)\n",
    "  return tf.reshape(one_hot_encoded, [-1, depth])\n",
    "\n",
    "\n",
    "def _fill_in_missing(x):\n",
    "  \"\"\"Replace missing values in a SparseTensor.\n",
    "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
    "  Args:\n",
    "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
    "      in the second dimension.\n",
    "  Returns:\n",
    "    A rank 1 tensor where missing values of `x` have been filled in.\n",
    "  \"\"\"\n",
    "  if not isinstance(x, tf.sparse.SparseTensor):\n",
    "    return x\n",
    "\n",
    "  default_value = '' if x.dtype == tf.string else 0\n",
    "  return tf.squeeze(\n",
    "      tf.sparse.to_dense(\n",
    "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "          default_value),\n",
    "      axis=1)\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
    "\n",
    "  Args:\n",
    "    inputs: map from feature keys to raw not-yet-transformed features.\n",
    "\n",
    "  Returns:\n",
    "    Map from string feature key to transformed feature operations.\n",
    "  \"\"\"\n",
    "  outputs = {}\n",
    "  for key in _NUMERICAL_FEATURES:\n",
    "    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.\n",
    "    outputs[t_name(key)] = tft.scale_to_z_score(\n",
    "        _fill_in_missing(inputs[key]), name=key)\n",
    "\n",
    "  for key in _BUCKET_FEATURES:\n",
    "    outputs[t_name(key)] = tf.cast(tft.bucketize(\n",
    "            _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT, name=key),\n",
    "            dtype=tf.float32)\n",
    "\n",
    "  for key in _CATEGORICAL_STRING_FEATURES:\n",
    "    outputs[t_name(key)] = _make_one_hot(_fill_in_missing(inputs[key]), key)\n",
    "\n",
    "  for key in _CATEGORICAL_NUMERICAL_FEATURES:\n",
    "    outputs[t_name(key)] = _make_one_hot(_fill_in_missing(inputs[key]), key)\n",
    "\n",
    "  # Was this passenger a big tipper?\n",
    "  taxi_fare = _fill_in_missing(inputs[_FARE_KEY])\n",
    "  tips = _fill_in_missing(inputs[_LABEL_KEY])\n",
    "  outputs[_LABEL_KEY] = tf.where(\n",
    "      tf.math.is_nan(taxi_fare),\n",
    "      tf.cast(tf.zeros_like(taxi_fare), tf.int64),\n",
    "      # Test if the tip was > 20% of the fare.\n",
    "      tf.cast(\n",
    "          tf.greater(tips, tf.multiply(taxi_fare, tf.constant(0.2))), tf.int64))\n",
    "\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1964661-1366-4abf-ab33-6d963263e23d",
   "metadata": {},
   "source": [
    "**Display the results of transforming some example data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740da0b3-8758-46f8-bb84-eaf1d99ffd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "    raw_examples = [\n",
    "        {\n",
    "            \"fare\": [100.0],\n",
    "            \"trip_start_hour\": [12],\n",
    "            \"pickup_census_tract\": ['abcd'],\n",
    "            \"dropoff_census_tract\": [12345], \n",
    "            \"company\": ['taxi inc.'],\n",
    "            \"trip_start_timestamp\": [123456],\n",
    "            \"pickup_longitude\": [12.0],\n",
    "            \"trip_start_month\": [5],\n",
    "            \"trip_miles\": [8.0],\n",
    "            \"dropoff_longitude\": [12.05],\n",
    "            \"dropoff_community_area\": [123],\n",
    "            \"pickup_community_area\": [123],\n",
    "            \"payment_type\": ['visa'],\n",
    "            \"trip_seconds\": [600],\n",
    "            \"trip_start_day\": [12],\n",
    "            \"tips\": [10.0],\n",
    "            \"pickup_latitude\": [80.0],\n",
    "            \"dropoff_latitude\": [80.01],\n",
    "        }\n",
    "    ]\n",
    "    (transformed_examples, transformed_metadata), transform_fn = (\n",
    "        (raw_examples, legacy_metadata)\n",
    "        | 'AnalyzeAndTransform' >> tft_beam.AnalyzeAndTransformDataset(\n",
    "            preprocessing_fn))\n",
    "    display(pd.DataFrame(transformed_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39829991-f5ec-462c-b7c0-a7275cd198dd",
   "metadata": {},
   "source": [
    "#### More advanced example\n",
    "The example presented here is really only meant to get you started. For a more advanced example see the [TensorFlow Transform Colab](https://www.tensorflow.org/tfx/tutorials/transform/census)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629cb1fd-8b9d-4deb-b333-dabe11aa8474",
   "metadata": {},
   "source": [
    "# Training\n",
    "Train a TensorFlow model with your nice, clean, transformed data.\n",
    "* Include the transformations from earlier so that they are applied consistently\n",
    "* Save the results as a SavedModel for production\n",
    "* Visualize and explore the training process using TensorBoard\n",
    "* Also save an EvalSavedModel for analysis of model performance\n",
    "\n",
    "[Trainer](https://www.tensorflow.org/tfx/guide/trainer) trains the model using TensorFlow [Estimators](https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/estimators.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80a05d-2f78-4498-b658-9311ed5d274f",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "\n",
    "Use the code below to run TensorBoard on the model in your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da898b0-09a7-4599-b1dc-bf16d1a7ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import webbrowser\n",
    "import tensorflow as tf\n",
    "\n",
    "!pip install -q tensorboard\n",
    "tf.get_logger().propagate = False\n",
    "\n",
    "pipeline_name = 'taxi'\n",
    "tensorboard_logdir = os.path.join(os.environ['HOME'], 'airflow/tfx/pipelines', pipeline_name, 'Trainer/model_run')\n",
    "print('tensorboard_logdir: {}'.format(tensorboard_logdir))\n",
    "#os.environ['TENSORBOARD_LOGDIR'] = tensorboard_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf04445-9596-4bdf-9a82-7c7aacafac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13b498-a641-4072-b4b7-93a2a044737b",
   "metadata": {},
   "source": [
    "**Start TensorBoard**\n",
    "\n",
    "Wait for TensorBoard to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f7637-95f4-457e-bb84-7d44df635254",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $tensorboard_logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e52ae8-2be6-48cb-b332-d6d78ebd5c13",
   "metadata": {},
   "source": [
    "#### More advanced example\n",
    "The example presented here is really only meant to get you started. For a more advanced example see the [TensorBoard Tutorial](https://www.tensorflow.org/tensorboard/get_started)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4fe724-4562-46dd-a4f2-7a8c2db9fa07",
   "metadata": {},
   "source": [
    "# Analyzing model performance\n",
    "Understanding more than just the top level metrics.\n",
    "* Users experience model performance for their queries only\n",
    "* Poor performance on slices of data can be hidden by top level metrics\n",
    "* Model fairness is important\n",
    "* Often key subsets of users or data are very important, and may be small\n",
    "  * Performance in critical but unusual conditions\n",
    "  * Performance for key audiences such as influencers\n",
    "* If youâ€™re replacing a model that is currently in production, first make sure that the new one is better\n",
    "* Evaluator tells the Pusher component if the model is OK\n",
    "\n",
    "[Evaluator](https://www.tensorflow.org/tfx/guide/evaluator) performs deep analysis of the training results, and ensures that the model is \"good enough\" to be pushed to production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc38ed-b3de-4b62-a20d-a913e0b299f4",
   "metadata": {},
   "source": [
    "Use the code below to run TensorFlow Model Analysis on the model in your pipeline. Start by importing and opening the metadata store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea139a-f477-4909-a9a8-c4b570da9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tfx_utils\n",
    "\n",
    "def _make_default_sqlite_uri(pipeline_name):\n",
    "    return os.path.join(os.environ['HOME'], 'airflow/tfx/metadata', pipeline_name, 'metadata.db')\n",
    "\n",
    "def get_metadata_store(pipeline_name):\n",
    "    return tfx_utils.TFXReadonlyMetadataStore.from_sqlite_db(_make_default_sqlite_uri(pipeline_name))\n",
    "\n",
    "pipeline_name = 'taxi' # or taxi_solution\n",
    "pipeline_db_path = _make_default_sqlite_uri(pipeline_name)\n",
    "print('Pipeline DB:\\n{}'.format(pipeline_db_path))\n",
    "\n",
    "store = get_metadata_store(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484b8c3-9df2-4420-b25d-ea4403dc8c9e",
   "metadata": {},
   "source": [
    "**Now print out the model artifacts:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b0e2a-5253-4e47-904f-5499132558fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4b4e8-53dc-4dd1-9b79-af5e656d8a1c",
   "metadata": {},
   "source": [
    "**Now analyze the model performance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f62e1-9c55-48d8-a6eb-2c8b3335545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.display_tfma_analysis(13, slicing_column='trip_start_hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83ed30-29ba-4977-94d1-861a82ff3131",
   "metadata": {},
   "source": [
    "**Now plot the artifact lineage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987531d-df3e-4f49-a359-3db04410b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different IDs here. Click stop in the plot when changing IDs.\n",
    "%matplotlib inline\n",
    "store.plot_artifact_lineage(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb28771-2580-49ea-9a2c-271d18c00906",
   "metadata": {},
   "source": [
    "# Ready for production\n",
    "\n",
    "If the new model is ready, make it so.\n",
    "* Pusher deploys SavedModels to well-known locations\n",
    "\n",
    "Deployment targets receive new models from well-known locations\n",
    "* TensorFlow Serving\n",
    "* TensorFlow Lite\n",
    "* TensorFlow JS\n",
    "* TensorFlow Hub\n",
    "\n",
    "[Pusher](https://www.tensorflow.org/tfx/guide/pusher) deploys the model to a serving infrastructure.\n",
    "\n",
    "# Next Steps\n",
    "You have now trained and validated your model, and exported a **SavedModel** file under the `~/airflow/saved_models/taxi` directory. Your model is now ready for production. You can now deploy your model to any of the TensorFlow deployment targets, including:\n",
    "\n",
    "[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving), for serving your model on a server or server farm and processing REST and/or gRPC inference requests.\n",
    "[TensorFlow Lite](https://www.tensorflow.org/lite), for including your model in an Android or iOS native mobile application, or in a Raspberry Pi, IoT, or microcontroller application.\n",
    "[TensorFlow.js](https://www.tensorflow.org/js), for running your model in a web browser or Node.JS application.#### More advanced example\n",
    "The example presented here is really only meant to get you started. For a more advanced example see the [TFMA Chicago Taxi Tutorial](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df32fc1-94eb-4817-b2e1-981cd542e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
