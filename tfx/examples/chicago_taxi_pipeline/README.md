# Chicago Taxi Example

The Chicago Taxi example demonstrates the end-to-end workflow and steps of how
to analyze, validate and transform data, train a model, analyze and serve it. It
uses the following [TFX](https://www.tensorflow.org/tfx) components:

* [ExampleGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/examplegen.md)
  ingests and splits the input dataset.
* [StatisticsGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/statsgen.md)
  calculates statistics for the dataset.
* [SchemaGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/schemagen.md)
  SchemaGen examines the statistics and creates a data schema.
* [ExampleValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/exampleval.md)
  looks for anomalies and missing values in the dataset.
* [Transform](https://github.com/tensorflow/tfx/blob/master/docs/guide/transform.md)
  performs feature engineering on the dataset.
* [Trainer](https://github.com/tensorflow/tfx/blob/master/docs/guide/trainer.md)
  trains the model using TensorFlow [Estimators](https://www.tensorflow.org/guide/estimators)
* [Evaluator](https://github.com/tensorflow/tfx/blob/master/docs/guide/evaluator.md)
  performs deep analysis of the training results.
* [ModelValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/modelval.md)
  ensures that the model is "good enough" to be pushed to production.
* [Pusher](https://github.com/tensorflow/tfx/blob/master/docs/guide/pusher.md)
  deploys the model to a serving infrastructure.
* [BulkInferrer](https://github.com/tensorflow/tfx/blob/master/docs/guide/bulk_inferrer.md)
  batch inference on the model with unlabelled examples.

Inference in the example is powered by:

* [TensorFlow Serving](https://www.tensorflow.org/serving) for serving.

## The dataset

This example uses the [Taxi Trips dataset](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew)
released by the City of Chicago.

Note: This site provides applications using data that has been modified
for use from its original source, www.cityofchicago.org, the official website of
the City of Chicago. The City of Chicago makes no claims as to the content,
accuracy, timeliness, or completeness of any of the data provided at this site.
The data provided at this site is subject to change at any time. It is
understood that the data provided at this site is being used at oneâ€™s own risk.

You can [read more](https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips)
about the dataset in [Google BigQuery](https://cloud.google.com/bigquery/).
Explore the full dataset in the
[BigQuery UI](https://bigquery.cloud.google.com/dataset/bigquery-public-data:chicago_taxi_trips).

## Local prerequisites

* [Apache Airflow](https://airflow.apache.org/) is used for pipeline orchestration.
* [Apache Beam](https://beam.apache.org/) is used for distributed processing.
* [TensorFlow](https://tensorflow.org) is used for model training, evaluation and inference.

### Install dependencies

Development for this example will be isolated in a Python virtual environment.
This allows us to experiment with different versions of dependencies.

There are many ways to install `virtualenv`, see the
[TensorFlow install guides](https://www.tensorflow.org/install) for different
platforms, but here are a couple:

* For Linux:

<pre class="devsite-terminal devsite-click-to-copy">
sudo apt-get install python-pip python-virtualenv python-dev build-essential
</pre>

* For Mac:

<pre class="devsite-terminal devsite-click-to-copy">
sudo easy_install pip
pip install --upgrade virtualenv
</pre>

Create a Python 3.6 virtual environment for this example and activate the
`virtualenv`:

<pre class="devsite-terminal devsite-click-to-copy">
virtualenv -p python3.6 taxi_pipeline
source ./taxi_pipeline/bin/activate
</pre>

Configure common paths:

<pre class="devsite-terminal devsite-click-to-copy">
export AIRFLOW_HOME=~/airflow
export TAXI_DIR=~/taxi
export TFX_DIR=~/tfx
</pre>

Next, install the dependencies required by the Chicago Taxi example:

<!--- bring back once requirements.txt file is available
<pre class="devsite-terminal devsite-click-to-copy">
pip install -r requirements.txt
</pre>
-->

<pre class="devsite-terminal devsite-click-to-copy">
pip install tensorflow==1.14.0
pip install apache-airflow==1.10.5
pip install tfx==0.14.0
</pre>

Next, initialize Airflow

<pre class="devsite-terminal devsite-click-to-copy">
airflow initdb
</pre>

### Copy the pipeline definition to Airflow's DAG directory

The benefit of the local example is that you can edit any part of the pipeline
and experiment very quickly with various components.  First let's download the
data for the example:

<pre class="devsite-terminal devsite-click-to-copy">
mkdir -p $TAXI_DIR/data/simple
wget -O $TAXI_DIR/data/simple/data.csv https://github.com/tensorflow/tfx/blob/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv?raw=true
</pre>

Next, copy the TFX pipeline definition to Airflow's <code>DAGs directory</code>
<code>($AIRFLOW_HOME/dags)</code> so it can run the pipeline.  To find the
location of your TFX installation, use this command:

<pre class="devsite-terminal devsite-click-to-copy">
pip show tfx
</pre>

Use the location shown when setting the TFX_EXAMPLES path below.

<pre class="devsite-terminal devsite-click-to-copy">
export TFX_EXAMPLES=~/taxi_pipeline/lib/python3.6/site-packages/tfx/examples/chicago_taxi_pipeline
</pre>

Copy the Chicago Taxi example pipeline into the Airflow DAG folder.

<pre class="devsite-terminal devsite-click-to-copy">
mkdir -p $AIRFLOW_HOME/dags/
cp $TFX_EXAMPLES/taxi_pipeline_simple.py $AIRFLOW_HOME/dags/
</pre>

The module file <code>taxi_utils.py</code> used by the Trainer and Transform
components will reside in $TAXI_DIR.  Copy it there.

<pre class="devsite-terminal devsite-click-to-copy">
cp $TFX_EXAMPLES/taxi_utils.py $TAXI_DIR
</pre>

## Run the local example

### Start Airflow

Start the <code>Airflow webserver</code> (in 'taxi_pipeline' virtualenv):

<pre class="devsite-terminal devsite-click-to-copy">
airflow webserver
</pre>

Open a new terminal window:

<pre class="devsite-terminal devsite-click-to-copy">
source ./taxi_pipeline/bin/activate
</pre>

and start the <code>Airflow scheduler</code>:

<pre class="devsite-terminal devsite-click-to-copy">
airflow scheduler
</pre>

Open a browser to <code>127.0.0.1:8080</code> and click on the <code>chicago_taxi_simple</code> example.
It should look like the image below if you click the Graph View option.

![Pipeline view](chicago_taxi_pipeline_simple.png)

### Run the example

If you were looking at the graph above, click on the <code>DAGs</code> button to
get back to the DAGs view.

Enable the <code>chicago_taxi_simple</code> pipeline in Airflow by toggling
the DAG to <code>On</code>.  Now that it is schedulable, click on the
<code>Trigger DAG button</code> (triangle inside a circle) to start the run. You
can view status by clicking on the started job, found in the
<code>Last run</code> column. This process will take several minutes.

### Serve the TensorFlow model

Once the pipeline completes, the model will be copied by the [Pusher](https://github.com/tensorflow/tfx/blob/master/docs/guide/pusher.md)
to the directory configured in the example code:

<pre class="devsite-terminal devsite-click-to-copy">
ls $TAXI_DIR/serving_model/chicago_taxi_simple
</pre>

Now serve the created model with
[TensorFlow Serving](https://www.tensorflow.org/serving). For this example, run
the server in a Docker container that is run locally. Instructions for
installing Docker locally are found in the
[Docker install documentation](https://docs.docker.com/install).

In the terminal, run the following script to start a server:

<pre class="devsite-terminal devsite-click-to-copy">
bash $TFX_EXAMPLES/serving/start_model_server_local.sh \
$TAXI_DIR/serving_model/chicago_taxi_simple
</pre>

This script pulls a TensorFlow Serving serving image and listens for for gRPC
requests on `localhost` port 9000. The model server loads the latest model
exported from the Pusher at above path.

To send a request to the server for model inference, run:

<pre class="devsite-terminal devsite-click-to-copy">
bash $TFX_EXAMPLES/serving/classify_local.sh \
$TAXI_DIR/data/simple/data.csv \
$TFX_DIR/pipelines/chicago_taxi_simple/SchemaGen/output/<b>CHANGE_TO_LATEST_DIR</b>/schema.pbtxt
</pre>

For Gooogle Cloud AI Platform serving example, use
`start_model_server_aiplatform.sh` and `classify_aiplatform.sh` in a similar way
as above local example with local directory changing to `gs://YOUR_BUCKET`.

For more information, see [TensorFlow Serving](https://www.tensorflow.org/serving).

# Chicago Taxi Flink Example

This section requires the [local prerequisites](#local_prerequisites) and adds a
few more for [Apache Flink](https://flink.apache.org/).

You need a local Apache Flink cluster and Java 8 to run the example locally on
Apache Flink. You will also need a Apache Beam Job Server running locally for
Apache Flink. Apache Beam and Flink setup script should be executed from within
a virtual environment. The script builds and updates the Apache Beam version
inside the virtual environment.

Create and activate a `virtualenv`, then setup the Flink environment:

<pre class="devsite-terminal devsite-click-to-copy">
bash $TFX_EXAMPLES/setup/setup_beam_on_flink.sh
</pre>

This will start a local Beam Job Server.
The Apache Flink UI can be viewed at http://localhost:8081.

To run tfx e2e on Flink, open a new terminal and activate another instance of
same `virtualenv`. Follow above instructions of Chicago Taxi Example with
'taxi_pipeline_simple' replaced by 'taxi_pipeline_portable_beam'.

# Chicago Taxi Spark Example

This section requires the [local prerequisites](#local_prerequisites) and adds a
few more for [Apache Spark](https://spark.apache.org/).

You need a local Apache Spark cluster and Java 8 to run the example locally on
Apache Spark. You will also need a Apache Beam Job Server running locally for
Apache Spark. Apache Beam and Spark setup script should be executed from within
a virtual environment. The script builds and updates the Apache Beam version
inside the virtual environment.

Create and activate a `virtualenv`, then setup the Spark environment:

<pre class="devsite-terminal devsite-click-to-copy">
bash $TFX_EXAMPLES/setup/setup_beam_on_spark.sh
</pre>

This will start a local Beam Job Server.
The Apache Spark UI can be viewed at http://localhost:8081. Check
http://localhost:4040 for the Spark application UI (while a job is running).


To run tfx e2e on Spark, open a new terminal and activate another instance of
same `virtualenv`. Follow above instructions of Chicago Taxi Example with
'taxi_pipeline_simple' replaced by 'taxi_pipeline_portable_beam'.

# Learn more

Please see the [TFX User Guide](https://github.com/tensorflow/tfx/blob/master/docs/guide/index.md) to learn more.
