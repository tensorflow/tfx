{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFX Iterative Development Example\n",
    "This notebook demonstrates how to use Jupyter notebooks for TFX iterative development.  Here, we walk through the Chicago Taxi example in an interactive Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, we import the necessary packages and set up paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import tfx\n",
    "from tfx.components.evaluator.component import Evaluator\n",
    "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
    "from tfx.components.example_validator.component import ExampleValidator\n",
    "from tfx.components.model_validator.component import ModelValidator\n",
    "from tfx.components.pusher.component import Pusher\n",
    "from tfx.components.schema_gen.component import SchemaGen\n",
    "from tfx.components.statistics_gen.component import StatisticsGen\n",
    "from tfx.components.trainer.component import Trainer\n",
    "from tfx.components.transform.component import Transform\n",
    "from tfx.orchestration.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import evaluator_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.utils.dsl_utils import csv_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example uses data installed as part of the TFX package.\n",
    "_taxi_root = os.path.join(tfx.__path__[0], 'examples/chicago_taxi_pipeline')\n",
    "_data_root = os.path.join(_taxi_root, 'data/simple')\n",
    "# Python module file to inject customized logic into the TFX components. The\n",
    "# Transform and Trainer both require user-defined functions to run successfully.\n",
    "_taxi_module_file = os.path.join(_taxi_root, 'taxi_utils.py')\n",
    "# Path which can be listened to by the model server.  Pusher will output the\n",
    "# trained model here.\n",
    "_serving_model_dir = os.path.join(tempfile.mkdtemp(), 'serving_model/taxi_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the InteractiveContext\n",
    "We now create the interactive context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we create an InteractiveContext using default parameters. This will\n",
    "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
    "# To use your own pipeline root or database, the optional properties\n",
    "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
    "# InteractiveContext.\n",
    "context = InteractiveContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TFX components interactively\n",
    "Next, we construct TFX components and run each one interactively using within the interactive session to obtain `ExecutionResult` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExampleGen\n",
    "`ExampleGen` brings data into the TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the packaged CSV input data.\n",
    "examples = csv_input(_data_root)\n",
    "\n",
    "# Brings data into the pipeline or otherwise joins/converts training data.\n",
    "example_gen = CsvExampleGen(input_base=examples)\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StatisticsGen\n",
    "`StatisticsGen` computes statistics for visualization and example validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes statistics over data for visualization and example validation.\n",
    "statistics_gen = StatisticsGen(\n",
    "    input_data=example_gen.outputs['examples'])\n",
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SchemaGen\n",
    "`SchemaGen` generates a schema for your data based on computed statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates schema based on statistics files.\n",
    "infer_schema = SchemaGen(stats=statistics_gen.outputs['output'])\n",
    "context.run(infer_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExampleValidator\n",
    "`ExampleValidator` performs anomaly detection based on computed statistics and your data schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs anomaly detection based on statistics and data schema.\n",
    "validate_stats = ExampleValidator(\n",
    "    stats=statistics_gen.outputs['output'],\n",
    "    schema=infer_schema.outputs['output'])\n",
    "context.run(validate_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "`Transform` performs data transformations and feature engineering which is kept in sync for training and serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs transformations and feature engineering in training and serving.\n",
    "transform = Transform(\n",
    "    input_data=example_gen.outputs['examples'],\n",
    "    schema=infer_schema.outputs['output'],\n",
    "    module_file=_taxi_module_file)\n",
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "`Trainer` trains your custom model using TF-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses user-provided Python function that implements a model using TF-Learn.\n",
    "trainer = Trainer(\n",
    "    module_file=_taxi_module_file,\n",
    "    transformed_examples=transform.outputs['transformed_examples'],\n",
    "    schema=infer_schema.outputs['output'],\n",
    "    transform_output=transform.outputs['transform_output'],\n",
    "    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
    "    eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n",
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator\n",
    "`Evaluator` computes evaluation statistics over features of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses TFMA to compute a evaluation statistics over features of a model.\n",
    "model_analyzer = Evaluator(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    model_exports=trainer.outputs['output'],\n",
    "    feature_slicing_spec=evaluator_pb2.FeatureSlicingSpec(specs=[\n",
    "        evaluator_pb2.SingleSlicingSpec(\n",
    "            column_for_slicing=['trip_start_hour'])\n",
    "    ]))\n",
    "context.run(model_analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelValidator\n",
    "`ModelValidator` performs validation of your candidate model compared to a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs quality validation of a candidate model (compared to a baseline).\n",
    "model_validator = ModelValidator(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    model=trainer.outputs['output'])\n",
    "context.run(model_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pusher\n",
    "`Pusher` checks whether a model has passed validation, and if so, pushes the model to a file destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks whether the model passed the validation steps and pushes the model\n",
    "# to a file destination if check passed.\n",
    "pusher = Pusher(\n",
    "    model_export=trainer.outputs['output'],\n",
    "    model_blessing=model_validator.outputs['blessing'],\n",
    "    push_destination=pusher_pb2.PushDestination(\n",
    "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "            base_directory=_serving_model_dir)))\n",
    "context.run(pusher)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}