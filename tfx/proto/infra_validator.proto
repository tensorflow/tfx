// Copyright 2019 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package tfx.components.infra_validator;

// ServingSpec defines an environment of the validating infrastructure: what
// (serving binary) and where (serving platform) to run model server.
message ServingSpec {

  // The kind of binary used to serve your model.This should be the same as the
  // one that is used in the pushing environment.
  //
  // It is often useful to validate multiple versions of the same serving binary
  // before pushing, and infra validator allows it. For example, you can specify
  // multiple versions of TensorFlow Serving image by setting:
  //
  //   {
  //     "tensorflow_serving": {
  //       "tags": ["1.15.0-gpu", "latest-gpu"]
  //     }
  //   }
  //
  // Infra validator will validate your model against both versions.
  oneof serving_binary {
    TensorFlowServing tensorflow_serving = 1;
  }

  // The kind of runtime platform for running your model server and
  // corresponding configuration.
  oneof serving_platform {
    LocalDockerConfig local_docker = 2;
  }
}

// TensorFlow Serving docker image (tensorflow/serving) for serving binary.
message TensorFlowServing {
  // Docker image tags to use such as "latest", "1.15.0-gpu", etc..
  repeated string tags = 1;

  // Alternative to `tags`, you can specify docker image `digests`, or even
  // both.
  repeated string digests = 2;
}

// Docker runtime in a local machine. This is useful when you're running
// pipeline with infra validator component in your your local machine. You need
// to install docker in advance.
message LocalDockerConfig {
  // Optional docker client base URL where docker server is hosted. Default to
  // your running platform's OS, e.g. "unix://var/run/docker.sock"
  string client_base_url = 1;
  // Optional docker API version to specify. Default to None, which will use the
  // installed docker version.
  string client_api_version = 2;
  // Optional docker client timeout seconds. Default to the constant defined in
  // docker-py library.
  int32 client_timeout_seconds = 3;
}

// Specification for validation criteria and thresholds.
message ValidationSpec {
  // If the model is not loaded until this time, validation will fail. Should
  // be a positive number.
  int32 max_loading_time_seconds = 1;
}

