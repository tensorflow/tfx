// Copyright 2020 Google LLC. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
syntax = "proto3";

package tfx.orchestration;

import "google/protobuf/any.proto";
import "google/protobuf/descriptor.proto";
import "ml_metadata/proto/metadata_store.proto";
import "tfx/proto/orchestration/placeholder.proto";

// ResolverConfig is subject to change. We plan to introduce a flexible
// config to enable more sophisticated policies in the future.
// TODO(b/152230663): Support more flexibility for resolution logic.
message ResolverConfig {
  // Each resolver step takes input map (Dict[Text, List[Artifact]]), process
  // the map, and optionally emits it (Optional[Dict[Text, List[Artifacts]]]).
  // If resolver step does not emit any input map, execution will not be
  // triggered.
  message ResolverStep {
    // Class path (<module_name>.<class_name>) of the resolver. For example
    // "tfx.dsl.resolvers.latest_artifact_strategy.LatestArtifactStrategy".
    // Resolver class should be the subclass of the
    // `tfx.dsl.components.common.resolver.ResolverStrategy` class.
    string class_path = 1;
    // JSON serialized resolver config which will be used as keyword arguments
    // on instantiating resolver class. Any tfx.utils.json_utils.Jsonable value
    // can be used.
    string config_json = 2;
    // Optional list of input keys that Resolver instance would use. Other keys
    // would bypass the resolver instance and passed as is to the next step. If
    // resolver returns None, bypassed inputs are also ignored and ResolverStep
    // would return None.
    // If not specified, all input keys will be used.
    repeated string input_keys = 3;
  }

  // Series of resolver steps that would be applied in order. Inputs and outputs
  // of resolver are the same (Dict[Text, List[Artifact]]), so the list of
  // resolvers can be composed to act as a single resolver. If any of such
  // composed resolvers returns None, the rest of the resolvers would not be
  // executed and early return None (which means component will not be
  // triggered).
  repeated ResolverStep resolver_steps = 1;
}

// Definition for runtime parameters.
message RuntimeParameter {
  enum Type {
    TYPE_UNSPECIFIED = 0;
    INT = 1;
    DOUBLE = 2;
    STRING = 3;
  }
  // Required field. The name of the runtime parameter. This should be globally
  // unique within the pipeline scope.
  string name = 1;
  // Required field. The type of the runtime parameter.
  Type type = 2;
  // Optional field. Default value of the runtime parameter. If not set and the
  // runtime parameter value is not provided during runtime, an error will be
  // raised.
  ml_metadata.Value default_value = 3;
}

// TODO(b/157270778): Support structural runtime parameter at the SDK level.
// Definition for structural runtime parameters.
// This can be used to combine several runtime parameters into a single string
// with parts of that being pre-set by users. Consider the following example:
//   `[RuntimeParameter(a), '_some_string_', RuntimeParameter(b)]`
// During runtime, the system will resolve the runtime parameters in the list
// and concatenate all pieces in the list together into a single string.
message StructuralRuntimeParameter {
  // Definition of each part in the structural runtime parameter. Each part can
  // be either a string or a runtime parameter.
  message StringOrRuntimeParameter {
    oneof value {
      string constant_value = 1;
      RuntimeParameter runtime_parameter = 2;
    }
  }
  repeated StringOrRuntimeParameter parts = 1;
}

// Definition for Value in uDSL IR. A Value instance can be one of: a field
// value that is determined during compilation time, a runtime parameter
// which will be determined during runtime, or a placeholder which will be
// determined during runtime / before / at execution time.
message Value {
  oneof value {
    ml_metadata.Value field_value = 1;
    RuntimeParameter runtime_parameter = 2;
    StructuralRuntimeParameter structural_runtime_parameter = 3;
    PlaceholderExpression placeholder = 5;
  }

  // If non-primitive types get JSON serialized and stored as string value in
  // ml_metadata.Value, ValueType provides necessary information to deserialize
  // the string and recover type information.
  message Schema {
    message ProtoType {
      string message_type = 1;
      google.protobuf.FileDescriptorSet file_descriptors = 2;
    }

    message BooleanType {}

    message ValueType {
      oneof type {
        ValueType list_type = 1;
        ProtoType proto_type = 2;
        BooleanType boolean_type = 3;
      }
    }

    ValueType value_type = 1;
  }
  Schema schema = 4;
}

// Definition of a predicate on property values. It can be one of the following:
// 1. A value comparator that predicates on a certain property and target value.
// 2. A unary logical operator that operates on a sub predicate.
// 3. A binary logical operator that operates on two sub predicates.
message PropertyPredicate {
  // Property value comparator.
  message ValueComparator {
    // Operators for comparison.
    enum Op {
      OP_UNSPECIFIED = 0;
      // The following two ops are available for all types.
      EQ = 1;
      LT = 2;
    }
    // The name of the property.
    string property_name = 1;
    // The target value to compare with.
    Value target_value = 2;
    Op op = 3;
    // Users can choose to set 0, 1 or 2 of the following two fields.
    //   - If none of them is set, the predicate is operated on single Artifact.
    //   - If only 'input_key' is set, the predicate is operated on
    //     Dict[Text, Artifact].
    //   - If only 'input_index' is set, the predicate is operated on
    //     List[Artifact].
    //   - If both 'input_key' and 'input_index' are set, the predicate is
    //     operated on Dict[Text, List[Artifact]].
    string input_key = 4;
    int32 input_index = 5;
  }
  // Logical operator on one element.
  message UnaryLogicalOperator {
    enum LogicalOp {
      OP_UNSPECIFIED = 0;
      NOT = 1;
    }
    LogicalOp op = 1;
    // The operand to operate on.
    PropertyPredicate operand = 2;
  }
  // Logical operator on two elements.
  message BinaryLogicalOperator {
    enum LogicalOp {
      OP_UNSPECIFIED = 0;
      AND = 1;
      OR = 2;
    }
    LogicalOp op = 1;
    // The left-hand side element to the logical operator.
    PropertyPredicate lhs = 2;
    // The right-hand side element to the logical operator.
    PropertyPredicate rhs = 3;
  }
  oneof operator {
    ValueComparator value_comparator = 1;
    UnaryLogicalOperator unary_logical_operator = 2;
    BinaryLogicalOperator binary_logical_operator = 3;
  }
}

// A proto message wrapping all information needed to query one set of artifacts
// from MLMD.
message InputSpec {
  message Channel {
    // Information to query the producer node of the artifacts.
    message ProducerNodeQuery {
      // The unique identifier of the node that produced the artifacts.
      string id = 1;
      // Predicate on producer node properties.
      PropertyPredicate property_predicate = 2;
    }
    // Information to query the contexts the desired artifacts are in.
    message ContextQuery {
      // The type of the Context.
      ml_metadata.ContextType type = 1;
      // The name of the context.
      Value name = 2;
      // Predicate on the context properties.
      PropertyPredicate property_predicate = 3;
    }
    // Information to query the desired artifacts.
    message ArtifactQuery {
      // The type of the artifact.
      ml_metadata.ArtifactType type = 1;
      // Predicate on the artifact properties.
      PropertyPredicate property_predicate = 2;
    }
    ProducerNodeQuery producer_node_query = 1;
    repeated ContextQuery context_queries = 2;
    ArtifactQuery artifact_query = 3;
    // The output key of the channel. Consider a `Trainer` with two output
    // channels: when downstream nodes consume its outputs, output key(s) need
    // to be specified:
    // ```
    // evaluator = tfx.Evaluator(model=trainer.outputs['some_output_key'])
    // ```
    // where 'some_output_key' is the output key for the channel that evaluator
    // uses as one of its input.
    string output_key = 4;
  }
  repeated Channel channels = 1;
  // The minimum number of artifacts desired. If minimum requirement is not met,
  // the execution should not be triggered. If min_count is less than or equal
  // to 0, it means this input is optional.
  int32 min_count = 2;
}

// The proto message describes specs of all inputs needed for a component
// execution.
message NodeInputs {
  // A map between the input tag and specs for the inputs of that tag.
  map<string, InputSpec> inputs = 1;
  // Optional resolver configs. This will apply on top of the results of all
  // inputs.
  ResolverConfig resolver_config = 2;
}

// A proto message wrapping all information needed to query one set of artifacts
// from MLMD.
message OutputSpec {
  // Information of the desired artifacts.
  message ArtifactSpec {
    // The name of the artifact type.
    ml_metadata.ArtifactType type = 1;
    // Additional properties to set when outputting artifacts.
    map<string, Value> additional_properties = 2;
    // Additional custom properties to set when outputting artifacts.
    map<string, Value> additional_custom_properties = 3;
  }
  ArtifactSpec artifact_spec = 1;
}

// TODO(b/163596295): Remove this along with other usages.
// Deprecated. Executor specification will be set in pipeline.deployment_config.
message ExecutorSpec {
  // Executor specification for Python-class based executors.
  message PythonClassExecutorSpec {
    // The full class path of the executor.
    string class_path = 1;
  }
  oneof spec {
    PythonClassExecutorSpec python_class_executor_spec = 1;
  }
}

// Spec of a context.
message ContextSpec {
  // The type of the context.
  ml_metadata.ContextType type = 1;
  // The name of the context.
  Value name = 2;
  // Properties of the context.
  map<string, Value> properties = 3;
}

// Basic info of a pipeline node, including the type and id of the node.
// The information in `NodeInfo` should stay stable across time. Asynchronous
// data fetching behavior might change if this changes.
message NodeInfo {
  // The MLMD type of the node. For example, is it an `ExampleGen` or `Trainer`.
  ml_metadata.ExecutionType type = 1;
  // The unique identifier of the node within the pipeline definition. This id
  // will be used in upstream and downstream nodes to indicate node
  // dependencies. This is generated by the system.
  string id = 2;
}

// Specifications of contexts that this node belongs to. All input artifacts,
// output artifacts and execution of the node will be linked to the (MLMD)
// contexts generated from these specifications.
message NodeContexts {
  repeated ContextSpec contexts = 1;
}
// Specifications for node outputs.
message NodeOutputs {
  map<string, OutputSpec> outputs = 1;
}
// Specifications for node parameters.
message NodeParameters {
  map<string, Value> parameters = 1;
}
// Options for executing the node.
message NodeExecutionOptions {
  message CachingOptions {
    // Whether or not to enable cache for this node.
    bool enable_cache = 1;
  }
  message Run {
    // If perform_snapshot is true, this node will perform the snapshot step.
    bool perform_snapshot = 1;
    // If depends_on_snapshot is true, the snapshot step must be complete before
    // this node's executor can run.
    // Note that it is possible for the node that performs the snapshot to
    // also have an executor that depends on the snapshot step.
    bool depends_on_snapshot = 2;
  }
  message Skip {
    // If reuse_artifacts is true, the snapshot operation will make sure that
    // output artifacts produced by this node in a previous pipeline run will
    // be made available in this partial run.
    bool reuse_artifacts = 1;
  }
  CachingOptions caching_options = 1;
  // Attached by platform-level tooling.
  oneof partial_run_option {
    // If set, this node will be run as part of the partial run.
    Run run = 2;
    // If set, this node will be skipped in the partial run.
    Skip skip = 3;
  }
}
// Pipeline node definition.
message PipelineNode {
  // Basic info of a pipeline node.
  NodeInfo node_info = 1;
  // Specification for contexts that this node belongs to.
  NodeContexts contexts = 2;
  // Specification for node inputs.
  NodeInputs inputs = 3;
  // Specification for node outputs.
  NodeOutputs outputs = 4;
  // Specification for node parameters.
  NodeParameters parameters = 5;
  // Specification for the executor of the node.
  ExecutorSpec executor = 6 [deprecated = true];
  // Ids of the upstream nodes of the current node.
  repeated string upstream_nodes = 7;
  // Ids of the downstream nodes of the current node.
  repeated string downstream_nodes = 8;
  // Options for executing the node.
  NodeExecutionOptions execution_options = 9;
}

// Settings used for snapshot during partial run.
// One of the nodes will call `partial_run_utils.snapshot(...)`, allowing this
// partial run to reuse artifacts from a previous pipeline run.
message SnapshotSettings {
  message LatestPipelineRunStrategy {}
  message BasePipelineRunStrategy {
    string base_run_id = 1;
  }
  oneof artifact_reuse_strategy {
    LatestPipelineRunStrategy latest_pipeline_run_strategy = 1;
    BasePipelineRunStrategy base_pipeline_run_strategy = 2;
  }
}

// Message struct that contains pipeline runtime specifications.
message PipelineRuntimeSpec {
  // Required field. Base directory of the pipeline. If not specified in DSL,
  // sub-pipelines will be compiled to use the same pipeline root as the parent
  // pipeline.
  Value pipeline_root = 1;
  // A unique id to identify a pipeline run. This will not be set during
  // compilation time but is required for synchronous pipeline execution.
  Value pipeline_run_id = 2;
  // Used for partial runs.
  SnapshotSettings snapshot_settings = 8;
}

// Basic info of a pipeline.
// The information in `PipelineInfo` should stay stable across time.
// Asynchronous data fetching behavior might change if this changes.
message PipelineInfo {
  // Required field. A pipeline must have an id.
  string id = 1;
}

// Definition for a uDSL pipeline. This is also the definition of a
// sub-pipeline.
message Pipeline {
  enum ExecutionMode {
    EXECUTION_MODE_UNSPECIFIED = 0;
    SYNC = 1;
    ASYNC = 2;
  }
  // A node inside a pipeline can be either a `PipelineNode` or a `Pipeline` as
  // a sub-pipeline.
  message PipelineOrNode {
    oneof node {
      // A normal pipeline node. This is the unsplittable execution unit.
      PipelineNode pipeline_node = 1;
      // Sub-pipelines should only have execution mode `SYNC`.
      Pipeline sub_pipeline = 2;
    }
  }

  PipelineInfo pipeline_info = 1;
  repeated PipelineOrNode nodes = 2;
  PipelineRuntimeSpec runtime_spec = 3;
  // Execution mode of the pipeline. Only the outermost pipeline can be `ASYNC`.
  ExecutionMode execution_mode = 4;
  // Deprecated. Please use 'deployment_config' instead.
  // Configs for different platforms, keyed by tags for different platforms that
  // users provide.
  map<string, google.protobuf.Any> platform_configs = 5 [deprecated = true];
  // Deployment config for the pipeline. This usually includes the following:
  //   - A map from `node_id` to executor specification. This should be set for
  //     all nodes that have business logic.
  //   - A map from `node_id` to custom driver specification. This should be set
  //     only when custom driver is involved which is a rare advanced use case.
  //   - A map from label to platform specific configs.
  //   - ML-metadata connection config.
  //   - Other configs.
  google.protobuf.Any deployment_config = 7;
  // TFX DSL SDK version for this pipeline.
  string sdk_version = 6;
}

// Definition of the intermediate 'deployment_config' generated by the general
// TFX DSL compiler. The result will be reinterpreted by different runners for
// different platforms.
message IntermediateDeploymentConfig {
  // A key from `node_id` to executor specs. Note that this will cover all nodes
  // that has business logic to process.
  map<string, google.protobuf.Any> executor_specs = 1;
  // A key from `node_id` to custom driver specs. Note that this map usually has
  // less entries than the `executor_specs` as we only expect advanced users to
  // set custom driver logic.
  map<string, google.protobuf.Any> custom_driver_specs = 2;
  // TODO(b/164108495): Figures out the DSL channel to set node level platform
  // configs.
  // A key from `node_id` to platform specs. This is placeholders for extra
  // platform related specifications which are set by users or platform runners
  // at node level.
  map<string, google.protobuf.Any> node_level_platform_configs = 3;
  // Pipeline level platform specific configs.
  google.protobuf.Any pipeline_level_platform_config = 4;
  // Connection config to ML-metadata.
  google.protobuf.Any metadata_connection_config = 5;
}

// Pipeline-level specifications for partial run that are exposed to users.
message PartialRun {
  // Source node ids.
  // Only run nodes that are reachable downstream from from_nodes (inclusive).
  repeated string from_nodes = 1;
  // Sink node ids.
  // Only run nodes that are reachable upstream from to_nodes (inclusive).
  repeated string to_nodes = 2;
  // Settings used for snapshot during partial run.
  SnapshotSettings snapshot_settings = 3;
}

// This is passed to the DAG runner when the pipeline is run.
// It is not part of the Pipeline IR.
message RunnerOptions {
  // Pipeline-level specifications for partial run.
  PartialRun partial_run = 1;
}
