{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdeKOEkv1Fe8"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpNWyqewk8fE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPxSVqcvqPHO"
      },
      "source": [
        "# TFX container component tutorial\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdRDkO2wQHUw"
      },
      "source": [
        "Warning: This tutorial requires Docker to be installed on your local machine.\n",
        "Because Google Colab doesn't support Docker, we recommend that you download\n",
        "this notebook and run it with Jupyter on your local machine.\n",
        "\n",
        "\u003cdiv class=\"devsite-table-wrapper\"\u003e\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "\u003ctd\u003e\u003ca target=\"_blank\" href=\"https://www.tensorflow.org/tfx/tutorials/tfx/container_component\"\u003e\n",
        "\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\u003c/td\u003e\n",
        "\u003ctd\u003e\u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/container_component.ipynb\"\u003e\n",
        "\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"\u003eRun in Google Colab\u003c/a\u003e\u003c/td\u003e\n",
        "\u003ctd\u003e\u003ca target=\"_blank\" href=\"https://github.com/tensorflow/tfx/tree/master/docs/tutorials/tfx/container_component.ipynb\"\u003e\n",
        "\u003cimg width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"\u003eView source on GitHub\u003c/a\u003e\u003c/td\u003e\n",
        "\u003ctd\u003e\u003ca target=\"_blank\" href=\"https://storage.googleapis.com/tensorflow_docs/tfx/docs/tutorials/tfx/container_component.ipynb\"\u003e\n",
        "\u003cimg width=32px src=\"https://www.tensorflow.org/images/download_logo_32px.png\"\u003eDownload notebook\u003c/a\u003e\u003c/td\u003e\n",
        "\u003c/table\u003e\u003c/div\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkwEwr0FQKJW"
      },
      "source": [
        "\n",
        "This notebook contains an examples on how to author and run container components\n",
        "within the TFX InteractiveContext and in a locally-orchestrated TFX\n",
        "pipeline.\n",
        "\n",
        "For more context and information, see the [Container component guide](https://www.tensorflow.org/tfx/guide/container_component)\n",
        "page on the TFX documentation site."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-Av6cm0oBFV"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We will first install TFX and import necessary modules. TFX requires Python 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwZ0aXisoBFW"
      },
      "source": [
        "### Check the system Python version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQ-QwavmqPHP",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDFSXMLLRGJC"
      },
      "source": [
        "### Install TFX\n",
        "\n",
        "**Note: In Google Colab, because of package updates, the first time you run\n",
        "this cell you must restart the runtime (Runtime \u003e Restart runtime ...).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGpQOmYIVlSV"
      },
      "outputs": [],
      "source": [
        "!pip install -U tfx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvXNj9a4VlSV"
      },
      "source": [
        "## Did you restart the runtime?\n",
        "\n",
        "If you are using Google Colab, the first time that you run the cell above, you\n",
        "must restart the runtime (Runtime \u003e Restart runtime ...). This is because of\n",
        "the way that Colab loads packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v45llP5ReKx"
      },
      "source": [
        "### Import packages\n",
        "We import TFX and check its version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRY0RFJ0VlSV"
      },
      "outputs": [],
      "source": [
        "# Check version\n",
        "import tfx\n",
        "tfx.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNDKmZJmnCr6"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "# Check Docker version\n",
        "try:\n",
        "  import colab\n",
        "except:\n",
        "  colab = None\n",
        "\n",
        "if not colab:\n",
        "  !docker version\n",
        "else:\n",
        "  print('Docker is not available in Google Colab. Download this tutorial and '\n",
        "        'run it locally in a Jupyter notebook to run container components.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvb0SspyqPH4"
      },
      "source": [
        "## Container-based custom components\n",
        "\n",
        "In this section, we will build components using containers and chain them\n",
        "together as a pipeline. This illustrates how we can pass data (using uris) to\n",
        "containers. This example uses well-known docker images for demo purposes, but\n",
        "users are expected to provide or build their own images when using\n",
        "container-based custom components.\n",
        "\n",
        "We will create a pipeline consists of two containers: in the first, we will\n",
        "execute shell commands to create a data file; in the second, we will hash\n",
        "the contents of that file.\n",
        "\n",
        "See the [container-based component\n",
        "guide](https://www.tensorflow.org/tfx/guide/container_component) for more\n",
        "documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHNtKTuiqPH4"
      },
      "outputs": [],
      "source": [
        "from tfx.types.experimental.simple_artifacts import Dataset\n",
        "from tfx.dsl.component.experimental.container_component import create_container_component\n",
        "from tfx.dsl.component.experimental import placeholders\n",
        "\n",
        "MyGenerator = create_container_component(\n",
        "    name='GenerateData',\n",
        "    outputs={\n",
        "        'data': Dataset,\n",
        "    },\n",
        "    # The component code uses gsutil to upload the data to Google Cloud Storage,\n",
        "    # so the container image needs to have gsutil installed and configured.\n",
        "    image = 'google/cloud-sdk:alpine',\n",
        "    command=[\n",
        "              'sh', '-exc',\n",
        "              '''\n",
        "              # Create a dummy file.\n",
        "              echo 'Dummy data' \u003e /tmp/data_file.txt\n",
        "\n",
        "              # Upload the file to GCS.\n",
        "              gsutil cp /tmp/data_file.txt \"${0}/\"\n",
        "              ''',\n",
        "              placeholders.OutputUriPlaceholder('data')  # Passed as ${0}\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtapXcbSqPH6"
      },
      "source": [
        "Next, we write a second component that uses the dummy data produced.\n",
        "This component will compute a hash using the parameterized `hash_command`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ZEf2xQqPH7"
      },
      "outputs": [],
      "source": [
        "from tfx.types.standard_artifacts import String\n",
        "\n",
        "MyConsumer = create_container_component(\n",
        "    name='ConsumeData',\n",
        "    inputs={\n",
        "        'data': Dataset,\n",
        "    },\n",
        "    outputs={\n",
        "        'hash': String,\n",
        "    },\n",
        "    parameters={\n",
        "        'hash_command': str,\n",
        "    },\n",
        "    image = 'google/cloud-sdk:alpine',\n",
        "    command=[\n",
        "              'sh', '-exc',\n",
        "              '''\n",
        "              # Calculate hash of the input file.\n",
        "              gsutil cat \"${0}/data_file.txt\" | \"${2}\" \u003e /tmp/hash\n",
        "\n",
        "              # Upload the result. Because the output is ValueArtifact,\n",
        "              # URI denotes a file in GCS.\n",
        "              gsutil cp /tmp/hash \"${1}\"\n",
        "              ''',\n",
        "              placeholders.InputUriPlaceholder('data'),  # Passed as ${0}\n",
        "              placeholders.OutputUriPlaceholder('hash'),  # ${1}\n",
        "              placeholders.InputValuePlaceholder('hash_command')  # ${2}\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvXKtg17O6mF"
      },
      "source": [
        "### Write a pipeline definition\n",
        "\n",
        "Next, we will author a pipeline using these same components. Defining\n",
        "a pipeline lets you deploy your pipeline on local or remote runners for\n",
        "production usage.\n",
        "\n",
        "Here, we will demonstrate usage of the LocalDagRunner running locally on your\n",
        "machine. For production execution, the Airflow or Kubeflow runners may\n",
        "be more suitable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft9fbSpnU7C6"
      },
      "source": [
        "#### Write a pipeline definition\n",
        "\n",
        "We can write a pipeline using the above components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOEfu2mytAl1"
      },
      "source": [
        "Warning: Because container-based components do not have direct access to any\n",
        "local filesystems, currently, when using container-based components, the TFX\n",
        "pipeline root should be on a remote filesystem like Google Cloud Storage (GCS),\n",
        "accessible from within the container. Credential handling and remote filesystem\n",
        "I/O need to be handled by logic within the container (this may be done\n",
        "automatically if running within a VM on a cloud provider)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIzihs4FtEYj"
      },
      "source": [
        "In our example, we set our pipeline root to be a location on Google Cloud\n",
        "Storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpkQ805-LyJu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.orchestration import pipeline\n",
        "\n",
        "# Select a persistent TFX root directory to store your output artifacts.\n",
        "# This needs to be changed to a location accessible by the executing container.\n",
        "PIPELINE_ROOT = 'gs://_MY_BUCKET_CHANGE_ME/tfx_root'\n",
        "# Select a pipeline name so that multiple runs of the same logical pipeline\n",
        "# can be grouped.\n",
        "PIPELINE_NAME = 'container-based-pipeline'\n",
        "# We use a ML Metadata configuration that uses a local SQLite database in\n",
        "# the pipeline root directory. Other backends for ML Metadata are available\n",
        "# for production usage.\n",
        "METADATA_CONNECTION_CONFIG = metadata.sqlite_metadata_connection_config(\n",
        "    os.path.join(PIPELINE_ROOT, 'metadata.sqlite'))\n",
        "\n",
        "def container_based_pipeline():\n",
        "  generator = MyGenerator()\n",
        "  consumer = MyConsumer(\n",
        "      data=generator.outputs['data'],\n",
        "      hash_command='sha256sum')\n",
        "\n",
        "  return pipeline.Pipeline(\n",
        "        pipeline_name=PIPELINE_NAME,\n",
        "        pipeline_root=PIPELINE_ROOT,\n",
        "        components=[generator, consumer],\n",
        "      metadata_connection_config=METADATA_CONNECTION_CONFIG)\n",
        "\n",
        "container_based_pipeline = container_based_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj-Z3cbFWPbK"
      },
      "source": [
        "#### Run your pipeline with the `LocalDagRunner`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLtGO2PkMQbO"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "from tfx.orchestration.local.local_dag_runner import LocalDagRunner\n",
        "\n",
        "if not colab:\n",
        "  LocalDagRunner().run(container_based_pipeline)\n",
        "else:\n",
        "  print('Google Colab does not support Docker container execution.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry4vU3mOWeN1"
      },
      "source": [
        "We can inspect the output artifacts generated by this pipeline execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyvYTsx8Mp1N"
      },
      "outputs": [],
      "source": [
        "# docs_infra: no_execute\n",
        "if not colab:\n",
        "  !find {PIPELINE_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4CsceadWqHp"
      },
      "source": [
        "You have now written your own custom components and orchestrated their\n",
        "execution on the LocalDagRunner! For next steps, check out additional tutorials\n",
        "and guides on the [TFX website](https://www.tensorflow.org/tfx)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wdeKOEkv1Fe8"
      ],
      "name": "TFX container component tutorial",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
